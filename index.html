
<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta content="IE=edge,chrome=1" http-equiv="X-UA-Compatible">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <title>AIbro Documentation</title>
    <script src="https://code.jquery.com/jquery-3.5.1.min.js"></script>
    <script type="text/javascript" src="source/javascripts/app/_copy.js"></script>
    <style media="screen">
      .highlight table td { padding: 5px; }
.highlight table pre { margin: 0; }
.highlight .gh {
  color: #999999;
}
.highlight .sr {
  color: #f6aa11;
}
.highlight .go {
  color: #888888;
}
.highlight .gp {
  color: #555555;
}
.highlight .gs {
}
.highlight .gu {
  color: #aaaaaa;
}
.highlight .nb {
  color: #f6aa11;
}
.highlight .cm {
  color: #75715e;
}
.highlight .cp {
  color: #75715e;
}
.highlight .c1 {
  color: #75715e;
}
.highlight .cs {
  color: #75715e;
}
.highlight .c, .highlight .ch, .highlight .cd, .highlight .cpf {
  color: #75715e;
}
.highlight .err {
  color: #960050;
}
.highlight .gr {
  color: #960050;
}
.highlight .gt {
  color: #960050;
}
.highlight .gd {
  color: #49483e;
}
.highlight .gi {
  color: #49483e;
}
.highlight .ge {
  color: #49483e;
}
.highlight .kc {
  color: #66d9ef;
}
.highlight .kd {
  color: #66d9ef;
}
.highlight .kr {
  color: #66d9ef;
}
.highlight .no {
  color: #66d9ef;
}
.highlight .kt {
  color: #66d9ef;
}
.highlight .mf {
  color: #ae81ff;
}
.highlight .mh {
  color: #ae81ff;
}
.highlight .il {
  color: #ae81ff;
}
.highlight .mi {
  color: #ae81ff;
}
.highlight .mo {
  color: #ae81ff;
}
.highlight .m, .highlight .mb, .highlight .mx {
  color: #ae81ff;
}
.highlight .sc {
  color: #ae81ff;
}
.highlight .se {
  color: #ae81ff;
}
.highlight .ss {
  color: #ae81ff;
}
.highlight .sd {
  color: #e6db74;
}
.highlight .s2 {
  color: #e6db74;
}
.highlight .sb {
  color: #e6db74;
}
.highlight .sh {
  color: #e6db74;
}
.highlight .si {
  color: #e6db74;
}
.highlight .sx {
  color: #e6db74;
}
.highlight .s1 {
  color: #e6db74;
}
.highlight .s, .highlight .sa, .highlight .dl {
  color: #e6db74;
}
.highlight .na {
  color: #a6e22e;
}
.highlight .nc {
  color: #a6e22e;
}
.highlight .nd {
  color: #a6e22e;
}
.highlight .ne {
  color: #a6e22e;
}
.highlight .nf, .highlight .fm {
  color: #a6e22e;
}
.highlight .vc {
  color: #ffffff;
}
.highlight .nn {
  color: #ffffff;
}
.highlight .ni {
  color: #ffffff;
}
.highlight .bp {
  color: #ffffff;
}
.highlight .vg {
  color: #ffffff;
}
.highlight .vi {
  color: #ffffff;
}
.highlight .nv, .highlight .vm {
  color: #ffffff;
}
.highlight .w {
  color: #ffffff;
}
.highlight {
  color: #ffffff;
}
.highlight .n, .highlight .py, .highlight .nx {
  color: #ffffff;
}
.highlight .nl {
  color: #f92672;
}
.highlight .ow {
  color: #f92672;
}
.highlight .nt {
  color: #f92672;
}
.highlight .k, .highlight .kv {
  color: #f92672;
}
.highlight .kn {
  color: #f92672;
}
.highlight .kp {
  color: #f92672;
}
.highlight .o {
  color: #f92672;
}
    </style>
    <style media="print">
      * {
        -webkit-transition:none!important;
        transition:none!important;
      }
      .highlight table td { padding: 5px; }
.highlight table pre { margin: 0; }
.highlight, .highlight .w {
  color: #586e75;
}
.highlight .err {
  color: #002b36;
  background-color: #dc322f;
}
.highlight .c, .highlight .ch, .highlight .cd, .highlight .cm, .highlight .cpf, .highlight .c1, .highlight .cs {
  color: #657b83;
}
.highlight .cp {
  color: #b58900;
}
.highlight .nt {
  color: #b58900;
}
.highlight .o, .highlight .ow {
  color: #93a1a1;
}
.highlight .p, .highlight .pi {
  color: #93a1a1;
}
.highlight .gi {
  color: #859900;
}
.highlight .gd {
  color: #dc322f;
}
.highlight .gh {
  color: #268bd2;
  background-color: #002b36;
  font-weight: bold;
}
.highlight .k, .highlight .kn, .highlight .kp, .highlight .kr, .highlight .kv {
  color: #6c71c4;
}
.highlight .kc {
  color: #cb4b16;
}
.highlight .kt {
  color: #cb4b16;
}
.highlight .kd {
  color: #cb4b16;
}
.highlight .s, .highlight .sb, .highlight .sc, .highlight .dl, .highlight .sd, .highlight .s2, .highlight .sh, .highlight .sx, .highlight .s1 {
  color: #859900;
}
.highlight .sa {
  color: #6c71c4;
}
.highlight .sr {
  color: #2aa198;
}
.highlight .si {
  color: #d33682;
}
.highlight .se {
  color: #d33682;
}
.highlight .nn {
  color: #b58900;
}
.highlight .nc {
  color: #b58900;
}
.highlight .no {
  color: #b58900;
}
.highlight .na {
  color: #268bd2;
}
.highlight .m, .highlight .mb, .highlight .mf, .highlight .mh, .highlight .mi, .highlight .il, .highlight .mo, .highlight .mx {
  color: #859900;
}
.highlight .ss {
  color: #859900;
}
    </style>
    <link href="stylesheets/screen-1d8a2b99.css" rel="stylesheet" media="screen" />
    <link href="stylesheets/print-953e3353.css" rel="stylesheet" media="print" />
      <script src="javascripts/all-c9c9fd69.js"></script>

    <script>
      $(function() { setupCodeCopy(); });
    </script>
  </head>

  <body class="index" data-languages="[&quot;python&quot;]">
    <a href="#" id="nav-button">
      <span>
        NAV
        <img src="images/navbar-cad8cdcb.png" alt="" />
      </span>
    </a>
    <div class="toc-wrapper">
      <img src="images/logo-5db5870f.png" class="logo" alt="" />
        <div class="lang-selector">
              <a href="#" data-language-name="python">python</a>
        </div>
        <div class="search">
          <input type="text" class="search" id="input-search" placeholder="Search">
        </div>
        <ul class="search-results"></ul>
      <ul id="toc" class="toc-list-h1">
          <li>
            <a href="#introduction-aibro-training" class="toc-h1 toc-link" data-title="Introduction - AIbro Training">Introduction - AIbro Training</a>
          </li>
          <li>
            <a href="#authentication" class="toc-h1 toc-link" data-title="Authentication">Authentication</a>
          </li>
          <li>
            <a href="#support-environment" class="toc-h1 toc-link" data-title="Support Environment">Support Environment</a>
          </li>
          <li>
            <a href="#start-the-first-training-job-on-aibro" class="toc-h1 toc-link" data-title="Start The First Training Job on AIbro">Start The First Training Job on AIbro</a>
              <ul class="toc-list-h2">
                  <li>
                    <a href="#step-1-install" class="toc-h2 toc-link" data-title="Step 1: Install">Step 1: Install</a>
                  </li>
                  <li>
                    <a href="#step-2-prepare-model-amp-data" class="toc-h2 toc-link" data-title="Step 2: Prepare model &amp; data">Step 2: Prepare model &amp; data</a>
                  </li>
                  <li>
                    <a href="#step-3-cloud-training-with-one-line-code" class="toc-h2 toc-link" data-title="Step 3: Cloud training with one-line code">Step 3: Cloud training with one-line code</a>
                  </li>
              </ul>
          </li>
          <li>
            <a href="#aibro-training" class="toc-h1 toc-link" data-title="aibro.training">aibro.training</a>
              <ul class="toc-list-h2">
                  <li>
                    <a href="#online_fit" class="toc-h2 toc-link" data-title="online_fit()">online_fit()</a>
                      <ul class="toc-list-h3">
                          <li>
                            <a href="#parameters" class="toc-h3 toc-link" data-title="Parameters">Parameters</a>
                          </li>
                      </ul>
                  </li>
                  <li>
                    <a href="#cooling-period" class="toc-h2 toc-link" data-title="Cooling Period">Cooling Period</a>
                  </li>
                  <li>
                    <a href="#distributed-training" class="toc-h2 toc-link" data-title="Distributed Training">Distributed Training</a>
                  </li>
              </ul>
          </li>
          <li>
            <a href="#aibro-job" class="toc-h1 toc-link" data-title="aibro.job">aibro.job</a>
              <ul class="toc-list-h2">
                  <li>
                    <a href="#get_tensorboard_logs" class="toc-h2 toc-link" data-title="get_tensorboard_logs()">get_tensorboard_logs()</a>
                      <ul class="toc-list-h3">
                          <li>
                            <a href="#parameters" class="toc-h3 toc-link" data-title="Parameters">Parameters</a>
                          </li>
                      </ul>
                  </li>
                  <li>
                    <a href="#plot_timeline" class="toc-h2 toc-link" data-title="plot_timeline()">plot_timeline()</a>
                      <ul class="toc-list-h3">
                          <li>
                            <a href="#parameters-2" class="toc-h3 toc-link" data-title="Parameters">Parameters</a>
                          </li>
                          <li>
                            <a href="#timeline" class="toc-h3 toc-link" data-title="Timeline">Timeline</a>
                          </li>
                      </ul>
                  </li>
                  <li>
                    <a href="#replay_job" class="toc-h2 toc-link" data-title="replay_job()">replay_job()</a>
                      <ul class="toc-list-h3">
                          <li>
                            <a href="#record-your-job" class="toc-h3 toc-link" data-title="Record your job">Record your job</a>
                          </li>
                          <li>
                            <a href="#parameters-3" class="toc-h3 toc-link" data-title="Parameters">Parameters</a>
                          </li>
                      </ul>
                  </li>
                  <li>
                    <a href="#training-job-amp-instance-status" class="toc-h2 toc-link" data-title="Training Job &amp; Instance Status">Training Job &amp; Instance Status</a>
                  </li>
              </ul>
          </li>
          <li>
            <a href="#aibro-comm" class="toc-h1 toc-link" data-title="aibro.comm">aibro.comm</a>
              <ul class="toc-list-h2">
                  <li>
                    <a href="#available_machines" class="toc-h2 toc-link" data-title="available_machines()">available_machines()</a>
                  </li>
                  <li>
                    <a href="#send_message" class="toc-h2 toc-link" data-title="send_message()">send_message()</a>
                      <ul class="toc-list-h3">
                          <li>
                            <a href="#parameters" class="toc-h3 toc-link" data-title="Parameters">Parameters</a>
                          </li>
                      </ul>
                  </li>
              </ul>
          </li>
          <li>
            <a href="#cloud-instance" class="toc-h1 toc-link" data-title="Cloud Instance">Cloud Instance</a>
              <ul class="toc-list-h2">
                  <li>
                    <a href="#spot-vs-on-demand-instance" class="toc-h2 toc-link" data-title="Spot Vs On-demand Instance">Spot Vs On-demand Instance</a>
                      <ul class="toc-list-h3">
                          <li>
                            <a href="#machine-id" class="toc-h3 toc-link" data-title="Machine id">Machine id</a>
                          </li>
                          <li>
                            <a href="#pricing" class="toc-h3 toc-link" data-title="Pricing">Pricing</a>
                          </li>
                          <li>
                            <a href="#availability" class="toc-h3 toc-link" data-title="Availability">Availability</a>
                          </li>
                          <li>
                            <a href="#reliability" class="toc-h3 toc-link" data-title="Reliability">Reliability</a>
                          </li>
                          <li>
                            <a href="#setup-speed" class="toc-h3 toc-link" data-title="Setup Speed">Setup Speed</a>
                          </li>
                      </ul>
                  </li>
              </ul>
          </li>
          <li>
            <a href="#contact-us" class="toc-h1 toc-link" data-title="Contact Us">Contact Us</a>
          </li>
          <li>
            <a href="#data-privacy" class="toc-h1 toc-link" data-title="Data Privacy">Data Privacy</a>
          </li>
      </ul>
        <ul class="toc-footer">
            <li><a href='https://aipaca.ai'>Sign Up to Get Start</a></li>
        </ul>
    </div>
    <div class="page-wrapper">
      <div class="dark-box"></div>
      <div class="content">
        <!-- ### HTTP Request

`GET http://example.com/api/kittens`

### Query Parameters

| Parameter    | Default | Description                                                                      |
| ------------ | ------- | -------------------------------------------------------------------------------- |
| include_cats | false   | If set to true, the result will also include cats.                               |
| available    | true    | If set to false, the result will include kittens that have already been adopted. | -->

<!-- <aside class="success">
Remember — a happy kitten is an authenticated kitten!
</aside>

## Get a Specific Kitten

```ruby
require 'kittn'

api = Kittn::APIClient.authorize!('meowmeowmeow')
api.kittens.get(2)
```

```python
import kittn

api = kittn.authorize('meowmeowmeow')
api.kittens.get(2)
```

```shell
curl "http://example.com/api/kittens/2" \
  -H "Authorization: meowmeowmeow"
```

```javascript
const kittn = require("kittn");

let api = kittn.authorize("meowmeowmeow");
let max = api.kittens.get(2);
```

> The above command returns JSON structured like this:

```json
{
  "id": 2,
  "name": "Max",
  "breed": "unknown",
  "fluffiness": 5,
  "cuteness": 10
}
```

This endpoint retrieves a specific kitten.

<aside class="warning">Inside HTML code blocks like this one, you can't use Markdown, so use <code>&lt;code&gt;</code> blocks to denote code.</aside>

### HTTP Request

`GET http://example.com/kittens/<ID>`

### URL Parameters

| Parameter | Description                      |
| --------- | -------------------------------- |
| ID        | The ID of the kitten to retrieve |

## Delete a Specific Kitten

```ruby
require 'kittn'

api = Kittn::APIClient.authorize!('meowmeowmeow')
api.kittens.delete(2)
```

```python
import kittn

api = kittn.authorize('meowmeowmeow')
api.kittens.delete(2)
```

```shell
curl "http://example.com/api/kittens/2" \
  -X DELETE \
  -H "Authorization: meowmeowmeow"
```

```javascript
const kittn = require("kittn");

let api = kittn.authorize("meowmeowmeow");
let max = api.kittens.delete(2);
```

> The above command returns JSON structured like this:

```json
{
  "id": 2,
  "deleted": ":("
}
```

This endpoint deletes a specific kitten.

### HTTP Request

`DELETE http://example.com/kittens/<ID>`

### URL Parameters

| Parameter | Description                    |
| --------- | ------------------------------ |
| ID        | The ID of the kitten to delete | -->
<h1 id='introduction-aibro-training'>Introduction - AIbro Training</h1>
<p><strong>AIbro Version</strong>: 1.1.1 <span style="color:blue;">(alpha)</span></p>

<p><strong>Last Documentation Update</strong>: Feb. 3, 2022</p>

<p><strong>Definition</strong>: API embedded python library</p>

<p>AIbro is a serverless MLOps tool that helps data scientists train &amp; deploy AI models on cloud platforms in two minutes.</p>

<p>Training is the first step in this process and is addressed by this document. The second step is deploying an inference model. For more information on deployment, please refer to the <a href="https://doc.aipaca.ai/inference">inference document</a>.</p>
<h1 id='authentication'>Authentication</h1>
<p>Authentication is required when Aibro APIs are called for the first time.</p>

<p>Albro allows one of the following two ways to authenticate:</p>

<ul>
<li>Access token (<strong>recommend</strong>): This is supplied using a series of characters prefixed by &quot;secret_...&quot;, and can be found in the Aibro Console on the <a href="https://aipaca.ai/humming">humming page</a>.</li>
<li>Email &amp; password: These credentials are the same that were used to register on the <a href="https://aipaca.ai">AIbro website</a>.</li>
</ul>

<p><em>ps: &quot;humming&quot; is literally how an alpaca &quot;greets&quot; people</em>😉</p>
<h1 id='support-environment'>Support Environment</h1>
<table><thead>
<tr>
<th>Framework</th>
<th>Version</th>
</tr>
</thead><tbody>
<tr>
<td>Tensorflow</td>
<td>&lt;= 2.5.1</td>
</tr>
</tbody></table>

<table><thead>
<tr>
<th>Cloud Platform</th>
<th>Spot Instance</th>
<th>On-demand Instance</th>
</tr>
</thead><tbody>
<tr>
<td>AWS</td>
<td>Yes</td>
<td>Yes</td>
</tr>
</tbody></table>

<table><thead>
<tr>
<th>Training Data Type</th>
<th>Maximum Data Size</th>
</tr>
</thead><tbody>
<tr>
<td><a href="https://numpy.org/">NumPy</a></td>
<td>2 GB</td>
</tr>
</tbody></table>

<table><thead>
<tr>
<th>Limit</th>
<th>Amount</th>
</tr>
</thead><tbody>
<tr>
<td>Max Active Jobs</td>
<td>5</td>
</tr>
<tr>
<td>Max Active Instances</td>
<td>5</td>
</tr>
<tr>
<td>Max Stopped Instances</td>
<td>4</td>
</tr>
</tbody></table>

<p>If your use case requires a different environment, such as one that is larger or otherwise not compatible, please feel free to <a href="#contact-us">Contact Us</a>. We are working hard to support additional environments and expect to have a variety of new options available shortly. Thank you for your patience.</p>
<h1 id='start-the-first-training-job-on-aibro'>Start The First Training Job on AIbro</h1>
<aside class="success">
Play around the executable Colab tutorial <a href = "https://colab.research.google.com/drive/19sXZ4kbic681zqEsrl_CZfB5cegUwuIB#forceEdit=true&sandboxMode=true&scrollTo=Et8ivBtkckme"> here</a>
</aside>
<h2 id='step-1-install'>Step 1: Install</h2><div class="highlight"><pre class="highlight python tab-python"><code><span class="n">pip</span> <span class="n">install</span> <span class="n">aibro</span>
</code></pre></div>
<p>The first step is to install the <a href="https://pypi.org/project/aibro/">Aibro Python library</a> using <code>pip</code>.</p>

<p>During the installation, if the <code>OSError: protocol now found</code> message appears, then it indicates an error caused by a missing file that can be easily resolved. The missing file is <code>/etc/protocols</code>, and entering the following command should remedy it.</p>

<p><code>sudo apt-get -o Dpkg::Options::=&quot;--force-confmiss&quot; install --reinstall netbase</code></p>
<h2 id='step-2-prepare-model-amp-data'>Step 2: Prepare model &amp; data</h2><div class="highlight"><pre class="highlight python tab-python"><code><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="n">tf</span>
<span class="kn">from</span> <span class="nn">tensorflow</span> <span class="kn">import</span> <span class="n">keras</span>
<span class="k">def</span> <span class="nf">get_mnist_data</span><span class="p">():</span>
    <span class="n">num_val_samples</span> <span class="o">=</span> <span class="mi">100</span>

    <span class="c1"># Return the MNIST dataset in the form of a [`tf.data.Dataset`]
</span>    <span class="c1"># reference: (https://www.tensorflow.org/api_docs/python/tf/data/Dataset).
</span>    <span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">),</span> <span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">datasets</span><span class="p">.</span><span class="n">mnist</span><span class="p">.</span><span class="n">load_data</span><span class="p">()</span>

    <span class="c1"># Preprocess the data (these are Numpy arrays)
</span>    <span class="n">x_train</span> <span class="o">=</span> <span class="n">x_train</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">784</span><span class="p">).</span><span class="n">astype</span><span class="p">(</span><span class="s">"float32"</span><span class="p">)</span> <span class="o">/</span> <span class="mi">255</span>
    <span class="n">x_test</span> <span class="o">=</span> <span class="n">x_test</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">784</span><span class="p">).</span><span class="n">astype</span><span class="p">(</span><span class="s">"float32"</span><span class="p">)</span> <span class="o">/</span> <span class="mi">255</span>
    <span class="n">y_train</span> <span class="o">=</span> <span class="n">y_train</span><span class="p">.</span><span class="n">astype</span><span class="p">(</span><span class="s">"float32"</span><span class="p">)</span>
    <span class="n">y_test</span> <span class="o">=</span> <span class="n">y_test</span><span class="p">.</span><span class="n">astype</span><span class="p">(</span><span class="s">"float32"</span><span class="p">)</span>

    <span class="c1"># Reserve num_val_samples samples for validation
</span>    <span class="n">x_val</span> <span class="o">=</span> <span class="n">x_train</span><span class="p">[</span><span class="o">-</span><span class="n">num_val_samples</span><span class="p">:]</span>
    <span class="n">y_val</span> <span class="o">=</span> <span class="n">y_train</span><span class="p">[</span><span class="o">-</span><span class="n">num_val_samples</span><span class="p">:]</span>
    <span class="n">x_train</span> <span class="o">=</span> <span class="n">x_train</span><span class="p">[:</span><span class="o">-</span><span class="n">num_val_samples</span><span class="p">]</span>
    <span class="n">y_train</span> <span class="o">=</span> <span class="n">y_train</span><span class="p">[:</span><span class="o">-</span><span class="n">num_val_samples</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">x_val</span><span class="p">,</span> <span class="n">y_val</span>


<span class="k">def</span> <span class="nf">get_compiled_FFNN_model</span><span class="p">():</span>
    <span class="c1"># Make a simple 2-layer densely-connected neural network.
</span>    <span class="n">inputs</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">784</span><span class="p">,))</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">"relu"</span><span class="p">)(</span><span class="n">inputs</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">"relu"</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="p">)</span>
    <span class="n">model</span><span class="p">.</span><span class="nb">compile</span><span class="p">(</span>
        <span class="n">optimizer</span><span class="o">=</span><span class="n">keras</span><span class="p">.</span><span class="n">optimizers</span><span class="p">.</span><span class="n">Adam</span><span class="p">(),</span>
        <span class="n">loss</span><span class="o">=</span><span class="n">keras</span><span class="p">.</span><span class="n">losses</span><span class="p">.</span><span class="n">SparseCategoricalCrossentropy</span><span class="p">(</span><span class="n">from_logits</span><span class="o">=</span><span class="bp">True</span><span class="p">),</span>
        <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="n">keras</span><span class="p">.</span><span class="n">metrics</span><span class="p">.</span><span class="n">SparseCategoricalAccuracy</span><span class="p">()],</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">model</span>


<span class="n">train_X</span><span class="p">,</span> <span class="n">train_Y</span><span class="p">,</span> <span class="n">validation_X</span><span class="p">,</span> <span class="n">validation_Y</span> <span class="o">=</span> <span class="n">get_mnist_data</span><span class="p">()</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">get_compiled_FFNN_model</span><span class="p">()</span>
</code></pre></div>
<p>As an example, we used a custom feed-forward neural network (FFNN) as the model, and the data from a <a href="https://www.tensorflow.org/api_docs/python/tf/data/Dataset">MNIST</a> dataset. If you choose an alternative model, please remember to confirm the model&#39;s compilability with the <a href="#support-environment">Support Environment</a>.</p>
<h2 id='step-3-cloud-training-with-one-line-code'>Step 3: Cloud training with one-line code</h2><div class="highlight"><pre class="highlight python tab-python"><code><span class="kn">from</span> <span class="nn">aibro.training</span> <span class="kn">import</span> <span class="n">Training</span>

<span class="n">job_id</span><span class="p">,</span> <span class="n">result_model</span><span class="p">,</span> <span class="n">history</span><span class="o">=</span> <span class="n">Training</span><span class="p">.</span><span class="n">online_fit</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
    <span class="n">train_X</span><span class="o">=</span><span class="n">train_X</span><span class="p">,</span>
    <span class="n">train_Y</span><span class="o">=</span><span class="n">train_Y</span><span class="p">,</span>
    <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">validation_X</span><span class="p">,</span> <span class="n">validation_Y</span><span class="p">),</span>
    <span class="n">machine_ids</span><span class="o">=</span><span class="p">[</span><span class="s">"p2.xlarge.od"</span><span class="p">],</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
    <span class="n">epochs</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span>
    <span class="n">description</span><span class="o">=</span><span class="s">"my first training job"</span><span class="p">,</span>
<span class="p">)</span>
</code></pre></div>
<p>After the model has been prepared, it is now time to train the model on the cloud. This is done using <strong>a single line of code:</strong>
<code>Training.online_fit()</code>.</p>

<p>Once the job begins, job status updates will be displayed on the <a href="https://aipaca.ai/jobs">Jobs page of AIbro Console</a> in real-time.</p>

<p>This example uses the basic <code>online_fit()</code> method for training. To explore more features, please refer to the <a href="#aibro-training">aibro.training</a> section.</p>
<h1 id='aibro-training'>aibro.training</h1><h2 id='online_fit'>online_fit()</h2><div class="highlight"><pre class="highlight python tab-python"><code><span class="k">def</span> <span class="nf">online_fit</span><span class="p">(</span>
    <span class="n">model</span><span class="p">:</span> <span class="n">tensorflow</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">models</span><span class="p">.</span><span class="n">Model</span><span class="p">,</span>
    <span class="n">train_X</span><span class="p">:</span> <span class="n">numpy</span><span class="p">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">train_Y</span><span class="p">:</span> <span class="n">numpy</span><span class="p">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">machine_ids</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">epochs</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">validation_data</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">]</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span>
    <span class="n">description</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s">""</span><span class="p">,</span>
    <span class="n">cool_down_period_s</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="n">fit_kwargs</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="p">{},</span>
    <span class="n">directory_to_save_ckpt</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span>
    <span class="n">directory_to_save_log</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span>
    <span class="n">wait_request_s</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">30</span><span class="p">,</span>
    <span class="n">wait_new_job_create_s</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">wait_new_job_create_interval</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span>
    <span class="n">record</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="bp">False</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">Optional</span><span class="p">[</span><span class="n">TF_Model</span><span class="p">],</span> <span class="n">Optional</span><span class="p">[</span><span class="n">History</span><span class="p">]]</span>
</code></pre></div>
<p>The <code>online_fit()</code> method is basically a synchronous fit operation. Once it is called, model fitting progress will be shown in real time. The &quot;online&quot; refers to the fact that it requires the internet connection persists during training. An <code>offline_fit()</code> method is currently being developed and is coming soon.</p>

<p>Every call to <code>online_fit()</code> will create a new training job, unless the maximum number of active jobs or instances per user has reached its limit.</p>

<p>The parameters are designed such that they are as close as possible to the TensorFlow style.</p>
<h3 id='parameters'>Parameters</h3>
<p><strong>model</strong>: <em>tensorflow.keras.models.Model</em><br/>
The machine learning model to be trained.</p>

<p><strong>train_X</strong>: <em>numpy.ndarray</em><br/>
The input portion of the training data supplied to the model.</p>

<p><strong>train_Y</strong>: <em>numpy.ndarray</em><br/>
The output portion, or target, of the training data that is supplied to the model. There is a one-to-one correspondence between the train_X vector and the train_Y vector such that Y should be predicted given X.</p>

<p><strong>machine_ids</strong>: <em>List[str] = None</em><br/>
This parameter is used to specify the cloud machines to be used for training the model. The machines are requested according to the order of the list. For example, in the case of <code>[&quot;p2. xlarge&quot;, &quot;g4dn.4xlarge&quot;]</code>, the API will try to request <code>p2.xlarge</code> first. If <code>p2.xlarge</code> is not available or has no capacity within <code>wait_request_s</code> seconds, <code>g4dn.4xlarge</code> will be requested next.</p>

<p>If <code>machine_ids</code> parameter is specified as <code>None</code>, a select-action message will pop up.</p>

<p><strong>batch_size</strong>: <em>int = 1</em><br/>
This parameter specifies the training batch size. If multiple GPUs are being utilized for training, it is recommended that the <code>batch_size</code> be set to a value that is a multiple of the number of GPUs. Please refer to the section on Distributed Training for (<a href="#distributed-training">more details</a>).</p>

<p><strong>epochs</strong>: <em>int = 1</em><br/>
This parameter is used to specify the number of training epochs.</p>

<p><strong>validation_data</strong>: <em>Tuple[np.array, np.array] = None</em><br/>
This parameter is used to specify the input and output validation data that is to be used by the model. The order is (validation_X, validation_Y).</p>

<p><strong>description</strong>: <em>str = &quot;&quot;</em><br/>
The description is used to briefly explain the training job. Setting a unique description for each job is recommend for easy lookup.</p>

<p><strong>cool_down_period_s</strong>: <em>int = 0</em><br/>
This specifies the time in seconds that an idle instance will be held before termination. <strong>This is an important concept</strong>. Please refer to the <a href="#cooling-period">Cooling Period</a> section for more details.</p>

<p><strong>fit_kwargs</strong>: <em>Dict[str, Any] = {}</em><br/>
The <code>fit_kwargs</code> parameter is used to pass arguments into the <code>model.fit()</code> method.</p>

<p><strong>directory_to_save_ckpt</strong>: <em>str = None</em><br/>
This parameter specifies the directory used to save checkpoints in your local machine. Checkpoints are stored per epoch. If the parameter is set to <code>None</code>, checkpoints will not be saved in the local machine.</p>

<p><strong>directory_to_save_log</strong>: <em>str = None</em><br/>
This parameter indicates which directory should be used to save the TensorBoard log file. If set to <code>None</code>, the log file will not be saved on the local machine.</p>

<p><strong>wait_request_s</strong>: <em>int = 10000</em><br/>
This parameter specifies the number of seconds that Aibro will wait for instance requests to be fulfilled. A large <code>wait_request_s</code> is helpful when requesting a spot instance with low availability.</p>

<p><strong>wait_new_job_create_s</strong>: <em>int = -1</em><br/>
This parameter specifies the number of seconds that Aibro will wait for a new job to be created. This parameter is helpful when the maximum active jobs or instances have been reached. It allows the new job to wait until one of the active jobs or instances are finished. If the value is non-positive, the new job will wait 99999999 seconds (basically indefinite).</p>

<p><strong>wait_new_job_create_interval</strong>: <em>int = 10</em><br/>
During the wait for a spot when creating a new job, Aibro will periodically check to see if there is one available. This parameter specifies the number of seconds in between checks.</p>

<p><strong>record</strong>: <em>bool = False</em><br/>
This parameter is used to turn record mode on or off, which can be helpful for troubleshooting and reporting issues. With record mode turned on, our support team can easily reproduce issues. Before using the feature, we recommend reading the <a href="#data-privacy">Privacy Items</a>.</p>
<h2 id='cooling-period'>Cooling Period</h2>
<p>The cooling period refers to the number of seconds that an idle instance will be held before termination. <strong>This is an important concept that should be carefully considered to maximize efficiency and minimize cost.</strong></p>

<p>To use cooling period, you should set the <code>cool_down_period_s</code> parameter to non-zero and request the same <code>machine_id</code> in your next job. Following this, Albro will automatically pick up the same instance for the next job. These are referred to as <strong>cooling instances</strong>.</p>

<p>The cooling period has the following benefits:</p>

<ul>
<li>Avoids environment gear-up time (approximately 5-6 mins). When a new instance is requested, it takes more than 5 minutes to mount the GPU and gear up TensorFlow
modules. On the other hand, cooling instances have no environment gear-up time.</li>
<li>Saving money. Time spent gearing-up the environment costs money, leading to savings when the gear-up time is reduced.</li>
</ul>

<p>We do not encourage users to set a long cooling period for spot instances because they are not always available. The cooling period may impact the capacity of other users. Therefore, if a spot instance is held for more than a <code>BASELINE</code> period, its price will increase by <code>UNIT_PERCENTAGE</code> per minute. After <code>1/UNIT_PERCENTAGE</code> minutes, its price will reach the maximum, which is the same as its on-demand price.</p>

<p>In this version, the variables are set as the following:</p>

<table><thead>
<tr>
<th>Variable</th>
<th>Value</th>
</tr>
</thead><tbody>
<tr>
<td>BASELINE</td>
<td>10 minutes</td>
</tr>
<tr>
<td>UNIT_PERCENTAGE</td>
<td>1%</td>
</tr>
</tbody></table>
<h2 id='distributed-training'>Distributed Training</h2>
<p>If a multi-GPU machine is selected (e.g. p3.8xlarge), Albro automatically trains the model with all available GPUs. Aibro uses TensortFlow’s <code>tf.distribute.MirroredStrategy</code> (<a href="https://www.tensorflow.org/api_docs/python/tf/distribute/MirroredStrategy">reference</a>) to implement synchronous training.</p>

<p>MirroredStrategy evenly shards batch data to each GPU. To increase GPU utility, the <strong>batch size</strong> should be set to a multiple of the number of GPUs. For instance, using a <code>p3.8xlarge</code>, the <code>batch_size</code> should be set to one of 4, 8, 16, etc, because it has 4 V100 GPUs.</p>
<h1 id='aibro-job'>aibro.job</h1><h2 id='get_tensorboard_logs'>get_tensorboard_logs()</h2><div class="highlight"><pre class="highlight python tab-python"><code><span class="k">def</span> <span class="nf">get_tensorboard_logs</span><span class="p">(</span>
    <span class="n">job_id</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">directory</span><span class="p">:</span> <span class="nb">str</span><span class="o">=</span><span class="s">"."</span>
<span class="p">)</span>
</code></pre></div>
<p>This method downloads the TensorBoard logs for a specific training job ID. The board can be opened by using a TensorBoard command such as <code>tensorboard --logdir logs</code>.</p>
<h3 id='parameters'>Parameters</h3>
<p><strong>job_id</strong>: <em>str</em><br/>
This parameter specifies the training job&#39;s ID.</p>

<p><strong>directory</strong>: <em>str</em> = &quot;.&quot;<br/>
This specifies the directory path to save the decoded TensorBoard log. By default, the log path is <code>{directory}/logs/{job_id}/</code>.</p>
<h2 id='plot_timeline'>plot_timeline()</h2><div class="highlight"><pre class="highlight python tab-python"><code><span class="k">def</span> <span class="nf">plot_timeline</span><span class="p">(</span><span class="n">job_id</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">char_type</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="bp">None</span><span class="p">)</span>
</code></pre></div>
<p>The <code>plot_timeline()</code> method is used to interpret the time spent training a job from end-to-end.</p>
<h3 id='parameters-2'>Parameters</h3>
<p><strong>job_id</strong>: <em>str</em><br/>
This parameter specifies the training job&#39;s ID.</p>

<p><strong>char_type</strong>: <em>str</em> = None<br/>
This refers to the type of chart to be used for the plot. If its value is <code>&quot;pie&quot;</code>, a pie chart would be plotted. Otherwise, it is a funnel chart.</p>
<h3 id='timeline'>Timeline</h3>
<p>The <code>plot_timeline()</code> method can be called at anytime, even prior to completion of the job.</p>

<p>The timeline provides greater insight than the job status.</p>

<p>From beginning to end, the following time periods are shown on timeline plots:</p>

<ul>
<li><strong>Job Create</strong>: This refers to the time spent between code execution and job creation.</li>
<li><strong>Request Launch</strong>: This is the time between a spot request start and when it is fulfilled. This period only applies to spot instances.</li>
<li><strong>Instance Connect</strong>: This period refers to the time after a request has been fulfilled to successfully establish an instance connection.</li>
<li><strong>API Transfer &amp; Server Setup</strong>: This is the time taken to set up the Albro API infrastructure in the instance.</li>
<li><strong>M&amp;D Serialization</strong>: This refers to the time used to serialize the model and training data.</li>
<li><strong>Env Gear up</strong>: This refers to the time spent to gear-up TensorFlow.</li>
<li><strong>M&amp;D Transfer</strong>: This refers to the time taken to transfer the model and training data from your local machine to the instance.</li>
<li><strong>M&amp;D Deserialization</strong>: This refers to the time used to deserialize the model and training data.</li>
<li><strong>Model Training</strong>: This is the time spent to train the model.</li>
<li><strong>Result Serialization</strong>: This is the time taken to serialize the trained model and other relevant objects.</li>
<li><strong>Result Transfer</strong>: This period refers to the time taken to transfer the trained model and other relevant objects.</li>
</ul>

<p><a href="https://aibro-user-timeline.s3.amazonaws.com/example/new_instance_timeline.html">Timeline Sample</a></p>
<h2 id='replay_job'>replay_job()</h2><div class="highlight"><pre class="highlight python tab-python"><code><span class="k">def</span> <span class="nf">replay_job</span><span class="p">(</span>
    <span class="n">job_id</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">description</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s">""</span><span class="p">,</span>
    <span class="n">directory_to_save_ckpt</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s">"."</span><span class="p">,</span>
    <span class="n">directory_to_save_log</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s">"."</span><span class="p">,</span>
    <span class="n">wait_request_s</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10000</span><span class="p">,</span>
<span class="p">)</span>
</code></pre></div>
<p>The <code>replay_job()</code> method is used to recreate the process involved with a job that was recorded using the record parameter. When a recorded job is submitted to the Aibro support team, they will use this method to reproduce the issue and work to resolve it.</p>

<p>In advance of sending the job to the Aibro support team, the <code>replay_job()</code> method can be employed to determine whether the reported issue is reproducible.</p>
<h3 id='record-your-job'>Record your job</h3>
<p>The Aibro team would appreciate it if you turned on the record parameter in <a href="#online_fit">online_fit()</a> before reporting an issue. In recorded jobs, Albro stores the model &amp; data to required to <a href="#replay_job">replay</a> the issue.</p>

<p><em>Note: Even though Aipaca only uses such data for service improvement purposes, &quot;record&quot; privacy items should be double-checked prior to sending the support team a recorded job. This is necessary to avoid violating the IP privacy of yourself or your agency. If extra privacy protection is needed, please do not hesitate to contact us by one of the ways above. Privacy is something we the Aipaca team takes seriously and is always here to help.</em></p>
<h3 id='parameters-3'>Parameters</h3>
<p><strong>job_id</strong>: <em>str</em><br/>
This parameter specifies the recorded job&#39;s ID.</p>

<p><strong>description</strong>: <em>str = &quot;&quot;</em><br/>
This is a textual description of the issue. Details included here will assist with diagnosing and resolving the issue.</p>

<p><strong>directory_to_save_ckpt</strong>: <em>str = None</em><br/>
This parameter specifies the directory used to save checkpoints in your local machine. Checkpoints are stored by per epoch. If the parameter is set to <code>None</code>, the model checkpoints will not be saved in the local machine.</p>

<p><strong>directory_to_save_log</strong>: <em>str = None</em><br/>
This parameter indicates which e directory should be used to save the TensorBoard log file. If set to <code>None</code>, the log file will not be saved on the your local machine.</p>

<p><strong>wait_request_s</strong>: <em>int = 10000</em><br/>
This parameter specifies the number of seconds that Aibro will wait for instance requests to be fulfilled. A long <code>wait_request_s</code> is helpful when requesting a spot instance with low availability.</p>
<h2 id='training-job-amp-instance-status'>Training Job &amp; Instance Status</h2>
<p>Once a job starts, its states and substates are updated on the <a href="https://aipaca.ai/jobs">Jobs page within the Albro Console</a>.</p>

<table><thead>
<tr>
<th>Job Status</th>
<th>Description</th>
</tr>
</thead><tbody>
<tr>
<td>QUEUING</td>
<td>Waiting for training</td>
</tr>
<tr>
<td>TRAINING</td>
<td>During training process or returning training results</td>
</tr>
<tr>
<td>CANCELED</td>
<td>Canceled due to some errors</td>
</tr>
<tr>
<td>COMPLETED</td>
<td>Completed the job</td>
</tr>
</tbody></table>

<table><thead>
<tr>
<th>Job Substatus</th>
<th>Description</th>
</tr>
</thead><tbody>
<tr>
<td>REQUESTING SERVER</td>
<td>Requesting an instance to train models</td>
</tr>
<tr>
<td>CONNECTING SERVER</td>
<td>Connecting an initializing instance</td>
</tr>
<tr>
<td>GEARING UP ENV</td>
<td>Gearing up tensorflow and mounting GPUs</td>
</tr>
<tr>
<td>SENDING MODEL &amp; DATA</td>
<td>Sending model and training data to the instance</td>
</tr>
<tr>
<td>TRAINING</td>
<td>Training model</td>
</tr>
<tr>
<td>RETURNING</td>
<td>Returning trained model</td>
</tr>
<tr>
<td>CANCELED</td>
<td>Canceled due to some errors</td>
</tr>
<tr>
<td>COMPLETED</td>
<td>Completed the job</td>
</tr>
</tbody></table>

<table><thead>
<tr>
<th>Instance Status</th>
<th>Description</th>
</tr>
</thead><tbody>
<tr>
<td>LAUNCHING</td>
<td>Setting up instance for training</td>
</tr>
<tr>
<td>EXECUTING</td>
<td>Having jobs in training process</td>
</tr>
<tr>
<td>COOLING</td>
<td>Within <a href="#cooling-period">Cooling Period</a></td>
</tr>
<tr>
<td>CLOSING</td>
<td>Stopping/terminating instance</td>
</tr>
<tr>
<td>CLOSED</td>
<td>instance has been stopped/terminated</td>
</tr>
</tbody></table>

<table><thead>
<tr>
<th>Instance Substatus</th>
<th>Description</th>
</tr>
</thead><tbody>
<tr>
<td>STOPPING/STOPPED</td>
<td>Shut down instance but retain root volume <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/Stop_Start.html">Reference</a></td>
</tr>
<tr>
<td>TERMINATING/TERMINATED</td>
<td>Completely delete the instance <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/terminating-instances.html">Reference</a></td>
</tr>
</tbody></table>

<p>In the AIbro usage case, <a href="#setup-speed">Setup speed</a> is the main advantage of stopped instance over terminated instance.</p>

<p>The following table is a status-substatus map of jobs and instances.</p>

<table><thead>
<tr>
<th>Job Status</th>
<th>Job Substatus</th>
<th>Instance Status</th>
<th>Instance Substatus</th>
</tr>
</thead><tbody>
<tr>
<td>QUEUING</td>
<td>REQUESTING SERVER</td>
<td></td>
<td></td>
</tr>
<tr>
<td>QUEUING</td>
<td>CONNECTING SERVER</td>
<td>LAUNCHING</td>
<td></td>
</tr>
<tr>
<td>QUEUING</td>
<td>GEARING UP ENV</td>
<td>LAUNCHING</td>
<td></td>
</tr>
<tr>
<td>QUEUING</td>
<td>SENDING MODEL &amp; DATA</td>
<td>LAUNCHING</td>
<td></td>
</tr>
<tr>
<td>----------</td>
<td>------------</td>
<td>----------------------</td>
<td>--------------------------</td>
</tr>
<tr>
<td>TRAINING</td>
<td>TRAINING</td>
<td>EXECUTING</td>
<td></td>
</tr>
<tr>
<td>TRAINING</td>
<td>RETURNING</td>
<td>EXECUTING</td>
<td></td>
</tr>
<tr>
<td>----------</td>
<td>------------</td>
<td>----------------------</td>
<td>--------------------------</td>
</tr>
<tr>
<td>CANCELED</td>
<td>CANCELED</td>
<td>COOLING/CLOSING/CLOSED</td>
<td>COOLING/(STOPPING, TERMINATING)/(STOPPED, TERMINATED)</td>
</tr>
<tr>
<td>COMPLETED</td>
<td>COMPLETED</td>
<td>COOLING/CLOSING/CLOSED</td>
<td>COOLING/(STOPPING, TERMINATING)/(STOPPED, TERMINATED)</td>
</tr>
</tbody></table>
<h1 id='aibro-comm'>aibro.comm</h1><h2 id='available_machines'>available_machines()</h2><div class="highlight"><pre class="highlight python tab-python"><code><span class="k">def</span> <span class="nf">available_machines</span><span class="p">()</span>

<span class="c1"># Sample Output:
# Machine Id: g4dn.12xlarge  GPU Type: 4xT4     num_vCPU: 48    cost: 1.43      capacity: 2 availability: 32.0%
# Machine Id: g4dn.12xlarge.od GPU Type: 4xT4     num_vCPU: 48    cost: 3.91      capacity: 3 availability: 100%
# Machine Id: g4dn.16xlarge  GPU Type: 1xT4     num_vCPU: 64    cost: 1.31      capacity: 2 availability: 13.0%
# Machine Id: g4dn.16xlarge.od GPU Type: 1xT4     num_vCPU: 64    cost: 4.35      capacity: 2 availability: 100%
# Machine Id: g4dn.4xlarge   GPU Type: 1xT4     num_vCPU: 16    cost: 0.36      capacity: 8 availability: 86.0%
</span></code></pre></div>
<p>The <code>available_machines()</code> method is used to retrieve machine information from the <a href="https://aipaca.ai/marketplace">Aibro Marketplace</a>.</p>

<p>There are two concepts in the marketplace, as follows:</p>

<ul>
<li><strong>Capacity</strong>: This refers to the number of instances that are requestable.</li>
<li><strong>Availability</strong>: The available is the success probability of an instance request.</li>
</ul>
<h2 id='send_message'>send_message()</h2><div class="highlight"><pre class="highlight python tab-python"><code><span class="k">def</span> <span class="nf">send_message</span><span class="p">(</span>
    <span class="n">email</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">feedback_message</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">category</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s">"random"</span>
<span class="p">)</span>
</code></pre></div>
<p>The <code>send_message()</code> method sends feedback directly to the Aibro support team.</p>
<h3 id='parameters'>Parameters</h3>
<p><strong>email</strong>: <em>str</em><br/>
This must be the email address that is registered with the account.</p>

<p><strong>feedback_message</strong>: <em>str</em><br/>
This parameter is used to provide message content. Basically, it is anything that you want to say to us.</p>

<p><strong>category</strong>: <em>str</em> = &quot;random&quot;<br/>
This is the category, or subject of the message. The category should be one of <code>[&#39;random&#39;, &#39;feature_request&#39;, or &#39;bug_report&#39;]</code>.</p>
<h1 id='cloud-instance'>Cloud Instance</h1>
<p>The words &quot;machine&quot;, &quot;server&quot;, and “instance” are used interchangeably in the following content.</p>
<h2 id='spot-vs-on-demand-instance'>Spot Vs On-demand Instance</h2><h3 id='machine-id'>Machine id</h3>
<p>By simply adding <code>&quot;.od&quot;</code> after the machine ID, it is converted from a spot instance to an on-demand instance (e.g. <em>p2.xlarge</em> is spot and <em>p2.xlarge.od</em> is on-demand).</p>
<h3 id='pricing'>Pricing</h3>
<p>Spot instances are usually 70% cheaper than their corresponding on-demand instances.</p>

<p><img src="https://drive.google.com/uc?export=view&amp;id=1G6fVuxUu8Yofj_SBxl57m_lFZ83L4MzE" alt="" />
<img src="https://drive.google.com/uc?export=view&amp;id=1vomqhv0C7-ZjmwZ62dv3bjFJZtL2-wiT" alt="" /></p>
<h3 id='availability'>Availability</h3>
<p>As a tradeoff, spot instance requests are not always fulfilled. We define <strong>&quot;availability&quot;</strong> as the success probability of an instance request.</p>

<p>Clearly, the availability of on-demand instances is always 100%. Provided there is sufficient capacity in the Aibro marketplace, an on-demand instance is guaranteed. There is a small chance that AWS will reach capacity and create a bottleneck, although this cannot be detected until the request encounters an error during a job.</p>

<p>The availability of spot instances is varied by instance type and request time. We have found that in general, the more powerful instance types have less availability (e.g. p3.2xlarge is less available than p2.xlarge). Not surprisingly, we have also found that spot instances are more often available during non-business hours.</p>
<h3 id='reliability'>Reliability</h3>
<p>When choosing a configuration, it is relevant that spot instances can be interrupted by AWS, whereas on-demand instances are always stable.</p>
<h3 id='setup-speed'>Setup Speed</h3>
<p>The <strong><a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/Stop_Start.html">stop</a></strong> feature allows on-demand instances to be set up faster than spot instances. This is the case because the first time a <strong>new</strong> instance is requested, TensorFlow needs approximately 5-7 minutes to gear up before the training starts. Unlike spot instances that can only be <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/terminating-instances.html"><strong>terminated</strong></a>, on-demand instances are stoppable, which reduces their subsequent gear-up time to between 0.5 and 1.5 minutes. Both instance types can set a <a href="#cooling-period">Cooling Period</a>, which, of course, won&#39;t have any gear-up time at all.</p>

<p>In addition to the longer gear-up time, a spot instance needs extra time to fulfill its request.</p>

<p>The following table compares the job timelines (refer to <a href="#plot_timeline">plot_timeline()</a>) of new, stopped, and cooling instances when training the same model &amp; data on the same instance.</p>

<table><thead>
<tr>
<th>Type</th>
<th>gear up time (minutes)</th>
<th>timeline</th>
</tr>
</thead><tbody>
<tr>
<td>new</td>
<td>5-7</td>
<td><a href="https://aibro-user-timeline.s3.amazonaws.com/example/new_instance_timeline.html">Timeline</a></td>
</tr>
<tr>
<td>stopped</td>
<td>0.5-1.5</td>
<td><a href="https://aibro-user-timeline.s3.amazonaws.com/example/stopped_instance_timeline.html">Timeline</a></td>
</tr>
<tr>
<td>cooling</td>
<td>0</td>
<td><a href="https://aibro-user-timeline.s3.amazonaws.com/example/cooling_server_timeline.html">Timeline</a></td>
</tr>
</tbody></table>
<h1 id='contact-us'>Contact Us</h1>
<p>If you have comments, questions, or concerns then please reach out to us in one of the following ways:</p>

<ol>
<li><strong>Recommended</strong>: We are available through the <a href="https://discord.gg/kEdtjUYb">Discord Community</a> and you can direct message our support team.</li>
<li>Use the &quot;Contact Us&quot; button on our <a href="https://aipaca.ai">website</a></li>
<li>Send us a message using the <a href="#send_message"><code>aibro.comm.Comm.send_message()</code></a></li>
<li>Email us at <a href = "mailto: hello@aipaca.ai">hello@aipaca.ai</a></li>
</ol>
<h1 id='data-privacy'>Data Privacy</h1>
<p>While using various features, Aibro requires access to data at different levels. Usually, the more access a feature needs, the better the user experience will be (i.e. more time or money savings). The choice of whether to use these features is up to the user. By default, the <code>online_fit()</code> methods will not have any access. The following table gives a privacy item overview for each feature.</p>

<table><thead>
<tr>
<th>Feature</th>
<th>Server access</th>
<th>Model Access</th>
<th>Data Access</th>
<th>Reason</th>
</tr>
</thead><tbody>
<tr>
<td>Cooling server</td>
<td><strong>Yes</strong></td>
<td>No</td>
<td>No</td>
<td>Aibro needs to retain the server access to reuse the cooling instances. The access will be permanently deleted once instances are terminated</td>
</tr>
<tr>
<td>Stopped server</td>
<td><strong>Yes</strong></td>
<td>No</td>
<td>No</td>
<td>Aibro needs to retain the server access to restart stopped instances. The access will be permanently deleted once instances are terminated</td>
</tr>
<tr>
<td>Report job</td>
<td>No</td>
<td><strong>Yes</strong></td>
<td><strong>Yes</strong></td>
<td>Support team needs the model &amp; data to replay the job and diagnose the reported issues</td>
</tr>
</tbody></table>

      </div>
      <div class="dark-box">
          <div class="lang-selector">
                <a href="#" data-language-name="python">python</a>
          </div>
      </div>
    </div>
  </body>
</html>
